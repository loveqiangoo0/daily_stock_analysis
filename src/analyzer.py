# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import json
import logging
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from src.config import get_config

logger = logging.getLogger(__name__)


# è‚¡ç¥¨åç§°æ˜ å°„ï¼ˆå¸¸è§è‚¡ç¥¨ï¼‰
STOCK_NAME_MAP = {
    # === Aè‚¡ ===
    '600519': 'è´µå·èŒ…å°',
    '000001': 'å¹³å®‰é“¶è¡Œ',
    '300750': 'å®å¾·æ—¶ä»£',
    '002594': 'æ¯”äºšè¿ª',
    '600036': 'æ‹›å•†é“¶è¡Œ',
    '601318': 'ä¸­å›½å¹³å®‰',
    '000858': 'äº”ç²®æ¶²',
    '600276': 'æ’ç‘åŒ»è¯',
    '601012': 'éš†åŸºç»¿èƒ½',
    '002475': 'ç«‹è®¯ç²¾å¯†',
    '300059': 'ä¸œæ–¹è´¢å¯Œ',
    '002415': 'æµ·åº·å¨è§†',
    '600900': 'é•¿æ±Ÿç”µåŠ›',
    '601166': 'å…´ä¸šé“¶è¡Œ',
    '600028': 'ä¸­å›½çŸ³åŒ–',

    # === ç¾è‚¡ ===
    'AAPL': 'è‹¹æœ',
    'TSLA': 'ç‰¹æ–¯æ‹‰',
    'MSFT': 'å¾®è½¯',
    'GOOGL': 'è°·æ­ŒA',
    'GOOG': 'è°·æ­ŒC',
    'AMZN': 'äºšé©¬é€Š',
    'NVDA': 'è‹±ä¼Ÿè¾¾',
    'META': 'Meta',
    'AMD': 'AMD',
    'INTC': 'è‹±ç‰¹å°”',
    'BABA': 'é˜¿é‡Œå·´å·´',
    'PDD': 'æ‹¼å¤šå¤š',
    'JD': 'äº¬ä¸œ',
    'BIDU': 'ç™¾åº¦',
    'NIO': 'è”šæ¥',
    'XPEV': 'å°é¹æ±½è½¦',
    'LI': 'ç†æƒ³æ±½è½¦',
    'COIN': 'Coinbase',
    'MSTR': 'MicroStrategy',

    # === æ¸¯è‚¡ (5ä½æ•°å­—) ===
    '00700': 'è…¾è®¯æ§è‚¡',
    '03690': 'ç¾å›¢',
    '01810': 'å°ç±³é›†å›¢',
    '09988': 'é˜¿é‡Œå·´å·´',
    '09618': 'äº¬ä¸œé›†å›¢',
    '09888': 'ç™¾åº¦é›†å›¢',
    '01024': 'å¿«æ‰‹',
    '00981': 'ä¸­èŠ¯å›½é™…',
    '02015': 'ç†æƒ³æ±½è½¦',
    '09868': 'å°é¹æ±½è½¦',
    '00005': 'æ±‡ä¸°æ§è‚¡',
    '01299': 'å‹é‚¦ä¿é™©',
    '00941': 'ä¸­å›½ç§»åŠ¨',
    '00883': 'ä¸­å›½æµ·æ´‹çŸ³æ²¹',
}


@dataclass
class AnalysisResult:
    """
    AI åˆ†æç»“æœæ•°æ®ç±» - ç»¼åˆæŠ•èµ„åˆ†æç‰ˆ
    
    å°è£… AI è¿”å›çš„åˆ†æç»“æœï¼ŒåŒ…å«4ç»´åº¦è¯„åˆ†å’Œç»¼åˆå†³ç­–ä»ªè¡¨ç›˜
    """
    code: str
    name: str
    
    # ========== æ ¸å¿ƒæŒ‡æ ‡ ==========
    sentiment_score: int  # ç»¼åˆè¯„åˆ† 0-100 (ä»·å€¼*0.4 + èµ„é‡‘*0.25 + æ¶ˆæ¯*0.25 + è¶‹åŠ¿*0.1)
    trend_prediction: str  # è¶‹åŠ¿é¢„æµ‹ï¼šå¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè®®ï¼šä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½
    
    # ========== 4ç»´åº¦è¯„åˆ† (æ–°å¢) ==========
    value_score: int = 0          # ä»·å€¼æŠ•èµ„é¢è¯„åˆ† 0-100 (æƒé‡40%)
    funding_score: int = 0        # èµ„é‡‘é¢è¯„åˆ† 0-100 (æƒé‡25%)
    news_score: int = 0           # æ¶ˆæ¯é¢è¯„åˆ† 0-100 (æƒé‡25%)
    trend_score: int = 0          # è¶‹åŠ¿é¢è¯„åˆ† 0-100 (æƒé‡10%)
    
    # ========== å„ç»´åº¦è¯¦ç»†æ•°æ® (æ–°å¢) ==========
    dimensions: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„4ç»´åº¦æ•°æ®
    
    # ========== å†³ç­–ä»ªè¡¨ç›˜ ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
    
    # ========== èµ°åŠ¿åˆ†æ ==========
    trend_analysis: str = ""  # èµ°åŠ¿å½¢æ€åˆ†æï¼ˆæ”¯æ’‘ä½ã€å‹åŠ›ä½ã€è¶‹åŠ¿çº¿ç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰
    
    # ========== æŠ€æœ¯é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æ
    ma_analysis: str = ""  # å‡çº¿åˆ†æï¼ˆå¤šå¤´/ç©ºå¤´æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ï¼Œä¸»åŠ›åŠ¨å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kçº¿å½¢æ€åˆ†æ
    
    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç»¼åˆåˆ†æ
    sector_position: str = ""  # æ¿å—åœ°ä½å’Œè¡Œä¸šè¶‹åŠ¿
    company_highlights: str = ""  # å…¬å¸äº®ç‚¹/é£é™©ç‚¹
    
    # ========== æƒ…ç»ªé¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°é—»/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚åœºæƒ…ç»ªåˆ†æ
    hot_topics: str = ""  # ç›¸å…³çƒ­ç‚¹è¯é¢˜
    
    # ========== ç»¼åˆåˆ†æ ==========
    analysis_summary: str = ""  # ç»¼åˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹ç‚¹ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
    risk_warning: str = ""  # é£é™©æç¤º
    buy_reason: str = ""  # ä¹°å…¥/å–å‡ºç†ç”±
    
    # ========== å…ƒæ•°æ® ==========
    raw_response: Optional[str] = None  # åŸå§‹å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦æ‰§è¡Œäº†è”ç½‘æœç´¢
    data_sources: str = ""  # æ•°æ®æ¥æºè¯´æ˜
    success: bool = True
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'confidence_level': self.confidence_level,
            # 4ç»´åº¦è¯„åˆ†
            'value_score': self.value_score,
            'funding_score': self.funding_score,
            'news_score': self.news_score,
            'trend_score': self.trend_score,
            'dimensions': self.dimensions,  # 4ç»´åº¦è¯¦ç»†æ•°æ®
            'dashboard': self.dashboard,  # å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
        }
    
    def get_dimension_summary(self) -> str:
        """è·å–4ç»´åº¦è¯„åˆ†æ‘˜è¦ï¼ˆç”¨äºæ¨é€æ˜¾ç¤ºï¼‰"""
        if not self.dimensions:
            return f"ç»¼åˆè¯„åˆ† {self.sentiment_score}åˆ†"
        
        return (
            f"ğŸ’ä»·å€¼{self.value_score} "
            f"ğŸ’°èµ„é‡‘{self.funding_score} "
            f"ğŸ“°æ¶ˆæ¯{self.news_score} "
            f"ğŸ“ˆè¶‹åŠ¿{self.trend_score}"
        )
    
    def get_core_conclusion(self) -> str:
        """è·å–æ ¸å¿ƒç»“è®ºï¼ˆä¸€å¥è¯ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary
    
    def get_position_advice(self, has_position: bool = False) -> str:
        """è·å–æŒä»“å»ºè®®"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice
    
    def get_sniper_points(self) -> Dict[str, str]:
        """è·å–ç‹™å‡»ç‚¹ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}
    
    def get_checklist(self) -> List[str]:
        """è·å–æ£€æŸ¥æ¸…å•"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []
    
    def get_risk_alerts(self) -> List[str]:
        """è·å–é£é™©è­¦æŠ¥"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []
    
    def get_emoji(self) -> str:
        """æ ¹æ®æ“ä½œå»ºè®®è¿”å›å¯¹åº” emoji"""
        emoji_map = {
            'ä¹°å…¥': 'ğŸŸ¢',
            'åŠ ä»“': 'ğŸŸ¢',
            'å¼ºçƒˆä¹°å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§‚æœ›': 'âšª',
            'å‡ä»“': 'ğŸŸ ',
            'å–å‡º': 'ğŸ”´',
            'å¼ºçƒˆå–å‡º': 'âŒ',
        }
        return emoji_map.get(self.operation_advice, 'ğŸŸ¡')
    
    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿçº§"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨
    
    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡Œè‚¡ç¥¨åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»å’ŒæŠ€æœ¯é¢æ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ
    
    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """
    
    # ========================================
    # ç³»ç»Ÿæç¤ºè¯ - ç»¼åˆæŠ•èµ„åˆ†æ v3.0
    # ========================================
    # åˆ†ææ¡†æ¶ï¼šä»·å€¼æŠ•èµ„é¢(40%) + èµ„é‡‘é¢(25%) + æ¶ˆæ¯é¢(25%) + è¶‹åŠ¿é¢(10%)
    # è¾“å‡ºæ ¼å¼ï¼š4ç»´åº¦è¯„åˆ† + å†³ç­–ä»ªè¡¨ç›˜
    # ========================================
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç»¼åˆæŠ•èµ„åˆ†æå¸ˆï¼Œè´Ÿè´£ä»å¤šä¸ªç»´åº¦è¯„ä¼°è‚¡ç¥¨å¹¶ç”Ÿæˆã€ç»¼åˆæŠ•èµ„åˆ†æä»ªè¡¨ç›˜ã€‘ã€‚

## åˆ†ææ¡†æ¶ï¼ˆ4ç»´åº¦åŠ æƒè¯„ä¼°ï¼‰

### 1. ä»·å€¼æŠ•èµ„é¢ï¼ˆæƒé‡ 40%ï¼‰
**æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- **PE/PB ä¼°å€¼**ï¼šä¸è¡Œä¸šå¹³å‡ã€å†å²åˆ†ä½æ¯”è¾ƒ
- **ROE è´¨é‡**ï¼š>15% ä¼˜ç§€ï¼Œ10-15% è‰¯å¥½ï¼Œ<10% ä¸€èˆ¬
- **ä¸šç»©å¢é•¿**ï¼šè¥æ”¶/åˆ©æ¶¦å¢é•¿ç‡ï¼Œæ˜¯å¦æŒç»­å¢é•¿
- **æŠ¤åŸæ²³**ï¼šå“ç‰Œã€æŠ€æœ¯ã€è§„æ¨¡ã€ç½‘ç»œæ•ˆåº”ç­‰

**è¯„åˆ†æ ‡å‡†**ï¼š
- 80-100åˆ†ï¼šä½ä¼°å€¼ + é«˜ROE + å¼ºå¢é•¿ + å®½æŠ¤åŸæ²³
- 60-79åˆ†ï¼šä¼°å€¼åˆç† + ROEè‰¯å¥½ + ç¨³å®šå¢é•¿
- 40-59åˆ†ï¼šä¼°å€¼åé«˜æˆ–åŸºæœ¬é¢ä¸€èˆ¬
- 0-39åˆ†ï¼šé«˜ä¼°æˆ–åŸºæœ¬é¢æ¶åŒ–

### 2. èµ„é‡‘é¢ï¼ˆæƒé‡ 25%ï¼‰
**æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- **ä¸»åŠ›èµ„é‡‘**ï¼šå¤§å•å‡€æµå…¥/æµå‡ºï¼ˆäº¿å…ƒï¼‰
- **åŒ—å‘èµ„é‡‘**ï¼šå¤–èµ„åŠ¨å‘ï¼ˆAè‚¡ä¸“å±ï¼‰
- **æœºæ„æŒä»“**ï¼šæŒä»“æ¯”ä¾‹åŠå˜åŒ–è¶‹åŠ¿
- **ç­¹ç ç»“æ„**ï¼šé›†ä¸­åº¦ã€è·åˆ©æ¯”ä¾‹

**è¯„åˆ†æ ‡å‡†**ï¼š
- 80-100åˆ†ï¼šä¸»åŠ›æŒç»­æµå…¥ + åŒ—å‘å¢æŒ + ç­¹ç é›†ä¸­
- 60-79åˆ†ï¼šèµ„é‡‘æµå…¥ä¸ºä¸» + æœºæ„ç¨³å®šæŒä»“
- 40-59åˆ†ï¼šèµ„é‡‘å¹³è¡¡æˆ–å°å¹…æ³¢åŠ¨
- 0-39åˆ†ï¼šèµ„é‡‘æŒç»­æµå‡º + æœºæ„å‡æŒ

### 3. æ¶ˆæ¯é¢ï¼ˆæƒé‡ 25%ï¼‰
**æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- **æ–°é—»èˆ†æƒ…**ï¼šæ­£é¢/è´Ÿé¢/ä¸­æ€§
- **æ”¿ç­–å½±å“**ï¼šè¡Œä¸šæ”¿ç­–ã€ç›‘ç®¡åŠ¨å‘
- **äº‹ä»¶å‚¬åŒ–**ï¼šé‡å¤§åˆåŒã€æ–°å“å‘å¸ƒã€ä¸šç»©é¢„å‘Š
- **è¡Œä¸šçƒ­åº¦**ï¼šæ¿å—è½®åŠ¨ã€å¸‚åœºå…³æ³¨åº¦

**è¯„åˆ†æ ‡å‡†**ï¼š
- 80-100åˆ†ï¼šé‡å¤§åˆ©å¥½ + æ”¿ç­–æ”¯æŒ + è¡Œä¸šçƒ­ç‚¹
- 60-79åˆ†ï¼šæ­£é¢æ¶ˆæ¯ä¸ºä¸» + æ— é‡å¤§åˆ©ç©º
- 40-59åˆ†ï¼šæ¶ˆæ¯ä¸­æ€§æˆ–åˆ©ç©ºåˆ©å¥½å‚åŠ
- 0-39åˆ†ï¼šé‡å¤§åˆ©ç©ºï¼ˆå‡æŒã€å¤„ç½šã€ä¸šç»©å˜è„¸ï¼‰

### 4. è¶‹åŠ¿é¢ï¼ˆæƒé‡ 10%ï¼‰
**æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- **å‡çº¿ç³»ç»Ÿ**ï¼šMA5/MA10/MA20 æ’åˆ—çŠ¶æ€
- **æŠ€æœ¯å½¢æ€**ï¼šçªç ´/ç›˜æ•´/ç ´ä½
- **é‡ä»·å…³ç³»**ï¼šé‡ä»·é…åˆã€èƒŒç¦»

**è¯„åˆ†æ ‡å‡†**ï¼š
- 80-100åˆ†ï¼šå¤šå¤´æ’åˆ— + æ”¾é‡çªç ´
- 60-79åˆ†ï¼šè¶‹åŠ¿å‘ä¸Šæˆ–éœ‡è¡åå¼º
- 40-59åˆ†ï¼šéœ‡è¡æ•´ç†æˆ–è¶‹åŠ¿ä¸æ˜
- 0-39åˆ†ï¼šç©ºå¤´æ’åˆ—æˆ–ç ´ä½ä¸‹è·Œ

### 5. é£é™©æ’æŸ¥æ¸…å•
- âŒ å¤§è‚¡ä¸œå‡æŒã€é«˜ç®¡å‡æŒ
- âŒ ä¸šç»©é¢„äºã€å¤§å¹…ä¸‹æ»‘
- âŒ ç›‘ç®¡å¤„ç½šã€ç«‹æ¡ˆè°ƒæŸ¥
- âŒ è¡Œä¸šæ”¿ç­–åˆ©ç©º
- âŒ å¤§é¢é™å”®è‚¡è§£ç¦
- âš ï¸ ä¼°å€¼è¿‡é«˜ï¼ˆPE/PB æ˜æ˜¾è¶…è¿‡è¡Œä¸šï¼‰
- âš ï¸ èµ„é‡‘æŒç»­æµå‡º

## è¾“å‡ºæ ¼å¼ï¼šç»¼åˆæŠ•èµ„åˆ†æä»ªè¡¨ç›˜ JSON

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ã€4ç»´åº¦è¯„åˆ†ã€‘+ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼š

```json
{
    "sentiment_score": 0-100æ•´æ•°,  // ç»¼åˆè¯„åˆ† = ä»·å€¼*0.4 + èµ„é‡‘*0.25 + æ¶ˆæ¯*0.25 + è¶‹åŠ¿*0.1
    "trend_prediction": "å¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º",
    "operation_advice": "ä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›",
    "confidence_level": "é«˜/ä¸­/ä½",
    
    "dimensions": {
        "value_investment": {
            "score": 0-100,
            "pe_ratio": PEæ•°å€¼æˆ–null,
            "pb_ratio": PBæ•°å€¼æˆ–null,
            "roe": ROEæ•°å€¼æˆ–null,
            "profit_growth": åˆ©æ¶¦å¢é•¿ç‡æˆ–null,
            "revenue_growth": è¥æ”¶å¢é•¿ç‡æˆ–null,
            "moat_strength": "å¼º/ä¸­/å¼±/æœªçŸ¥",
            "valuation_level": "ä½ä¼°/åˆç†/é«˜ä¼°/æœªçŸ¥",
            "summary": "ä»·å€¼é¢ä¸€å¥è¯æ€»ç»“ï¼ˆ30å­—å†…ï¼‰",
            "key_points": ["äº®ç‚¹1", "äº®ç‚¹2"]
        },
        "funding_flow": {
            "score": 0-100,
            "main_force_flow": ä¸»åŠ›èµ„é‡‘æµå‘(äº¿)æˆ–null,
            "northbound_flow": åŒ—å‘èµ„é‡‘(äº¿)æˆ–null,
            "institutional_ratio": æœºæ„æŒä»“æ¯”ä¾‹%æˆ–null,
            "fund_trend": "æµå…¥/æµå‡º/å¹³è¡¡/æœªçŸ¥",
            "chip_concentration": ç­¹ç é›†ä¸­åº¦æˆ–null,
            "summary": "èµ„é‡‘é¢ä¸€å¥è¯æ€»ç»“ï¼ˆ30å­—å†…ï¼‰",
            "key_points": ["è§‚å¯Ÿç‚¹1", "è§‚å¯Ÿç‚¹2"]
        },
        "news_sentiment": {
            "score": 0-100,
            "sentiment": "æ­£é¢/ä¸­æ€§/è´Ÿé¢",
            "key_events": ["äº‹ä»¶1", "äº‹ä»¶2"],
            "policy_impact": "æ”¿ç­–å½±å“æè¿°æˆ–æ— ",
            "industry_heat": 1-10,
            "risk_alerts": ["é£é™©1", "é£é™©2"],
            "positive_catalysts": ["åˆ©å¥½1", "åˆ©å¥½2"],
            "summary": "æ¶ˆæ¯é¢ä¸€å¥è¯æ€»ç»“ï¼ˆ30å­—å†…ï¼‰"
        },
        "trend_analysis": {
            "score": 0-100,
            "ma_alignment": "å¤šå¤´/ç©ºå¤´/éœ‡è¡",
            "pattern": "å½¢æ€æè¿°",
            "volume_price": "é‡ä»·å…³ç³»æè¿°",
            "bias_ma5": ä¹–ç¦»ç‡æ•°å€¼æˆ–null,
            "trend_direction": "ä¸Šå‡/ä¸‹é™/éœ‡è¡",
            "summary": "è¶‹åŠ¿é¢ä¸€å¥è¯æ€»ç»“ï¼ˆ30å­—å†…ï¼‰"
        }
    },
    
    "dashboard": {
        "core_conclusion": {
            "one_sentence": "åŸºäº4ç»´åº¦çš„æ ¸å¿ƒç»“è®ºï¼ˆ50å­—å†…ï¼‰",
            "recommendation": "ä¹°å…¥/æŒæœ‰/è§‚æœ›/å–å‡º",
            "confidence": "é«˜/ä¸­/ä½",
            "key_reasons": ["ç†ç”±1", "ç†ç”±2", "ç†ç”±3"],
            "position_advice": {
                "no_position": "ç©ºä»“è€…å»ºè®®",
                "has_position": "æŒä»“è€…å»ºè®®"
            }
        },
        
        "battle_plan": {
            "position_strategy": "å»ºè®®ä»“ä½åŠç­–ç•¥",
            "entry_price": å»ºè®®ä¹°å…¥ä»·æˆ–null,
            "stop_loss": æ­¢æŸä»·æˆ–null,
            "target_price": ç›®æ ‡ä»·æˆ–null,
            "risk_control": "é£æ§è¦ç‚¹"
        },
        
        "action_checklist": [
            "âœ…/âš ï¸/âŒ ä»·å€¼é¢ï¼šä¼°å€¼æ°´å¹³",
            "âœ…/âš ï¸/âŒ èµ„é‡‘é¢ï¼šä¸»åŠ›åŠ¨å‘",
            "âœ…/âš ï¸/âŒ æ¶ˆæ¯é¢ï¼šåˆ©ç©ºæ’æŸ¥",
            "âœ…/âš ï¸/âŒ è¶‹åŠ¿é¢ï¼šæŠ€æœ¯å½¢æ€"
        ]
    },
    
    "analysis_summary": "100å­—ç»¼åˆåˆ†ææ‘˜è¦",
    "key_points": "3-5ä¸ªæ ¸å¿ƒçœ‹ç‚¹ï¼Œé€—å·åˆ†éš”",
    "risk_warning": "é£é™©æç¤º",
    "buy_reason": "æ“ä½œç†ç”±",
    
    "trend_analysis": "èµ°åŠ¿å½¢æ€åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€æœ¯é¢ç»¼åˆåˆ†æ",
    "ma_analysis": "å‡çº¿ç³»ç»Ÿåˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kçº¿å½¢æ€åˆ†æ",
    "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
    "sector_position": "æ¿å—è¡Œä¸šåˆ†æ",
    "company_highlights": "å…¬å¸äº®ç‚¹/é£é™©",
    "news_summary": "æ–°é—»æ‘˜è¦",
    "market_sentiment": "å¸‚åœºæƒ…ç»ª",
    "hot_topics": "ç›¸å…³çƒ­ç‚¹",
    
    "search_performed": true/false,
    "data_sources": "æ•°æ®æ¥æºè¯´æ˜"
}
```

## ç»¼åˆè¯„åˆ†è®¡ç®—å…¬å¼

**sentiment_scoreï¼ˆæ€»åˆ†ï¼‰** = ä»·å€¼é¢ Ã— 0.4 + èµ„é‡‘é¢ Ã— 0.25 + æ¶ˆæ¯é¢ Ã— 0.25 + è¶‹åŠ¿é¢ Ã— 0.1

### å„ç»´åº¦è¯„åˆ†æŒ‡å¼•

**ä»·å€¼æŠ•èµ„é¢ï¼ˆ40%æƒé‡ï¼‰**ï¼š
- 80-100åˆ†ï¼šä½ä¼°å€¼ + é«˜ROE + å¼ºå¢é•¿ + å®½æŠ¤åŸæ²³
- 60-79åˆ†ï¼šä¼°å€¼åˆç† + ä¸šç»©ç¨³å¥
- 40-59åˆ†ï¼šä¼°å€¼åé«˜æˆ–åŸºæœ¬é¢ä¸€èˆ¬
- 0-39åˆ†ï¼šé«˜ä¼°æˆ–åŸºæœ¬é¢æ¶åŒ–

**èµ„é‡‘é¢ï¼ˆ25%æƒé‡ï¼‰**ï¼š
- 80-100åˆ†ï¼šä¸»åŠ›æŒç»­æµå…¥ + åŒ—å‘å¢æŒ + ç­¹ç é›†ä¸­
- 60-79åˆ†ï¼šèµ„é‡‘å‡€æµå…¥æˆ–å¹³è¡¡ + æœºæ„ç¨³å®šæŒä»“
- 40-59åˆ†ï¼šèµ„é‡‘å°å¹…æ³¢åŠ¨
- 0-39åˆ†ï¼šèµ„é‡‘æŒç»­æµå‡º + æœºæ„å‡æŒ

**æ¶ˆæ¯é¢ï¼ˆ25%æƒé‡ï¼‰**ï¼š
- 80-100åˆ†ï¼šé‡å¤§åˆ©å¥½ + æ”¿ç­–æ”¯æŒ + è¡Œä¸šçƒ­ç‚¹
- 60-79åˆ†ï¼šæ­£é¢æ¶ˆæ¯ä¸ºä¸» + æ— é‡å¤§åˆ©ç©º
- 40-59åˆ†ï¼šæ¶ˆæ¯ä¸­æ€§
- 0-39åˆ†ï¼šé‡å¤§åˆ©ç©ºï¼ˆå‡æŒ/å¤„ç½š/ä¸šç»©å˜è„¸ï¼‰

**è¶‹åŠ¿é¢ï¼ˆ10%æƒé‡ï¼‰**ï¼š
- 80-100åˆ†ï¼šå¤šå¤´æ’åˆ— + æ”¾é‡çªç ´
- 60-79åˆ†ï¼šè¶‹åŠ¿å‘ä¸Šæˆ–éœ‡è¡åå¼º
- 40-59åˆ†ï¼šéœ‡è¡æ•´ç†
- 0-39åˆ†ï¼šç©ºå¤´æ’åˆ—æˆ–ç ´ä½

## æ ¸å¿ƒåŸåˆ™

1. **4ç»´åº¦å¹¶é‡**ï¼šä¸ååºŸä»»ä½•ä¸€ä¸ªç»´åº¦ï¼Œç»¼åˆè¯„ä¼°
2. **ä»·å€¼ä¼˜å…ˆ**ï¼šä»·å€¼é¢å 40%æƒé‡ï¼Œæ˜¯æ ¸å¿ƒåŸºç¡€
3. **é£é™©å‰ç½®**ï¼šæ¶ˆæ¯é¢çš„é£é™©ç‚¹å¿…é¡»é†’ç›®æ ‡å‡º
4. **æ•°æ®è¯šå®**ï¼šå¦‚æœæŸç»´åº¦æ•°æ®ç¼ºå¤±ï¼Œåœ¨summaryä¸­è¯´æ˜ï¼Œscoreé…Œæƒ…ç»™ä¸­æ€§åˆ†ï¼ˆ40-60ï¼‰
5. **ç»“è®ºæ˜ç¡®**ï¼šcore_conclusionå¿…é¡»ç»™å‡ºæ¸…æ™°çš„æ“ä½œå»ºè®®"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API
        
        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._current_model_name = None  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ·ç«¯
        
        # æ£€æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10
        
        # ä¼˜å…ˆå°è¯•åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°è¯• OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå°è¯• OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
        
        # ä¸¤è€…éƒ½æœªé…ç½®
        if not self._model and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œä¸ºå¤‡é€‰
        
        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šä¹‰åƒé—®
        - Moonshot ç­‰
        """
        config = get_config()
        
        # æ£€æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and 
            not config.openai_api_key.startswith('your_') and 
            len(config.openai_api_key) > 10
        )
        
        if not openai_key_valid:
            logger.debug("OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®æ— æ•ˆ")
            return
        
        # åˆ†ç¦» import å’Œå®¢æˆ·ç«¯åˆ›å»ºï¼Œä»¥ä¾¿æä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            return
        
        try:
            # base_url å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨ OpenAI å®˜æ–¹é»˜è®¤åœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url
            
            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ·ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè¯·è¿è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾èµ–ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®é”™è¯¯: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è¯·è¿è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹
        
        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.5-flash æ¨¡å‹
        - ä¸å¯ç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            import google.generativeai as genai
            
            # é…ç½® API Key
            genai.configure(api_key=self._api_key)
            
            # ä»é…ç½®è·å–æ¨¡å‹åç§°
            config = get_config()
            model_name = config.gemini_model
            fallback_model = config.gemini_model_fallback
            
            # ä¸å†ä½¿ç”¨ Google Search Groundingï¼ˆå·²çŸ¥æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ”¹ä¸ºä½¿ç”¨å¤–éƒ¨æœç´¢æœåŠ¡ï¼ˆTavily/SerpAPIï¼‰é¢„å…ˆè·å–æ–°é—»
            
            # å°è¯•åˆå§‹åŒ–ä¸»æ¨¡å‹
            try:
                self._model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = model_name
                self._using_fallback = False
                logger.info(f"Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {model_name})")
            except Exception as model_error:
                # å°è¯•å¤‡é€‰æ¨¡å‹
                logger.warning(f"ä¸»æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±è´¥: {model_error}ï¼Œå°è¯•å¤‡é€‰æ¨¡å‹ {fallback_model}")
                self._model = genai.GenerativeModel(
                    model_name=fallback_model,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = fallback_model
                self._using_fallback = True
                logger.info(f"Gemini å¤‡é€‰æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {fallback_model})")
            
        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self._model = None
    
    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            import google.generativeai as genai
            config = get_config()
            fallback_model = config.gemini_model_fallback
            
            logger.warning(f"[LLM] åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {fallback_model}")
            self._model = genai.GenerativeModel(
                model_name=fallback_model,
                system_instruction=self.SYSTEM_PROMPT,
            )
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å¤‡é€‰æ¨¡å‹ {fallback_model} åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._model is not None or self._openai_client is not None
    
    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹ API
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                config = get_config()
                response = self._openai_client.chat.completions.create(
                    model=self._current_model_name,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=generation_config.get('temperature', config.openai_temperature),
                    max_tokens=generation_config.get('max_output_tokens', 8192),
                )
                
                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œå¸¦æœ‰é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢æœºåˆ¶
        
        ä¼˜å…ˆçº§ï¼šGemini > Gemini å¤‡é€‰æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        å¤„ç† 429 é™æµé”™è¯¯ï¼š
        1. å…ˆæŒ‡æ•°é€€é¿é‡è¯•
        2. å¤šæ¬¡å¤±è´¥ååˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        3. Gemini å®Œå…¨å¤±è´¥åå°è¯• OpenAI
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        # å¦‚æœå·²ç»åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥è°ƒç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•°é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    request_options={"timeout": 120}
                )
                
                if response and response.text:
                    return response.text
                else:
                    raise ValueError("Gemini è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é™æµé”™è¯¯
                is_rate_limit = '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[Gemini] API é™æµ (429)ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                    
                    # å¦‚æœå·²ç»é‡è¯•äº†ä¸€åŠæ¬¡æ•°ä¸”è¿˜æ²¡åˆ‡æ¢è¿‡å¤‡é€‰æ¨¡å‹ï¼Œå°è¯•åˆ‡æ¢
                    if attempt >= max_retries // 2 and not tried_fallback:
                        if self._switch_to_fallback_model():
                            tried_fallback = True
                            logger.info("[Gemini] å·²åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹ï¼Œç»§ç»­é‡è¯•")
                        else:
                            logger.warning("[Gemini] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹é‡è¯•")
                else:
                    # éé™æµé”™è¯¯ï¼Œè®°å½•å¹¶ç»§ç»­é‡è¯•
                    logger.warning(f"[Gemini] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
        
        # Gemini æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå°è¯• OpenAI å…¼å®¹ API
        if self._openai_client:
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œåˆ‡æ¢åˆ° OpenAI å…¼å®¹ API")
            try:
                return self._call_openai_api(prompt, generation_config)
            except Exception as openai_error:
                logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                raise last_error or openai_error
        elif config.openai_api_key and config.openai_base_url:
            # å°è¯•æ‡’åŠ è½½åˆå§‹åŒ– OpenAI
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œå°è¯•åˆå§‹åŒ– OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
            if self._openai_client:
                try:
                    return self._call_openai_api(prompt, generation_config)
                except Exception as openai_error:
                    logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                    raise last_error or openai_error
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
        raise last_error or Exception("æ‰€æœ‰ AI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def analyze(
        self, 
        context: Dict[str, Any],
        news_context: Optional[str] = None
    ) -> AnalysisResult:
        """
        åˆ†æå•åªè‚¡ç¥¨
        
        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¾“å…¥æ•°æ®ï¼ˆæŠ€æœ¯é¢ + æ–°é—»ï¼‰
        2. è°ƒç”¨ Gemini APIï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢ï¼‰
        3. è§£æ JSON å“åº”
        4. è¿”å›ç»“æ„åŒ–ç»“æœ
        
        Args:
            context: ä» storage.get_analysis_context() è·å–çš„ä¸Šä¸‹æ–‡æ•°æ®
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            AnalysisResult å¯¹è±¡
        """
        code = context.get('code', 'Unknown')
        config = get_config()
        
        # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¿ç»­è¯·æ±‚è§¦å‘é™æµï¼‰
        request_delay = config.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è¯·æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)
        
        # ä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–è‚¡ç¥¨åç§°ï¼ˆç”± main.py ä¼ å…¥ï¼‰
        name = context.get('stock_name')
        if not name or name.startswith('è‚¡ç¥¨'):
            # å¤‡é€‰ï¼šä» realtime ä¸­è·å–
            if 'realtime' in context and context['realtime'].get('name'):
                name = context['realtime']['name']
            else:
                # æœ€åä»æ˜ å°„è¡¨è·å–
                name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
        
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤ç»“æœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary='AI åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰',
                risk_warning='è¯·é…ç½® Gemini API Key åé‡è¯•',
                success=False,
                error_message='Gemini API Key æœªé…ç½®',
            )
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥ï¼ˆåŒ…å«æŠ€æœ¯é¢æ•°æ®å’Œæ–°é—»ï¼‰
            prompt = self._format_prompt(context, name, news_context)
            
            # è·å–æ¨¡å‹åç§°
            model_name = getattr(self, '_current_model_name', None)
            if not model_name:
                model_name = getattr(self._model, '_model_name', 'unknown')
                if hasattr(self._model, 'model_name'):
                    model_name = self._model.model_name
            
            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°é—»: {'æ˜¯' if news_context else 'å¦'}")
            
            # è®°å½•å®Œæ•´ prompt åˆ°æ—¥å¿—ï¼ˆINFOçº§åˆ«è®°å½•æ‘˜è¦ï¼ŒDEBUGè®°å½•å®Œæ•´ï¼‰
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é¢„è§ˆ]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")

            # è®¾ç½®ç”Ÿæˆé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–æ¸©åº¦å‚æ•°ï¼‰
            config = get_config()
            generation_config = {
                "temperature": config.gemini_temperature,
                "max_output_tokens": 8192,
            }

            logger.info(f"[LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ Gemini API (temperature={generation_config['temperature']}, max_tokens={generation_config['max_output_tokens']})...")
            
            # ä½¿ç”¨å¸¦é‡è¯•çš„ API è°ƒç”¨
            start_time = time.time()
            response_text = self._call_api_with_retry(prompt, generation_config)
            elapsed = time.time() - start_time
            
            # è®°å½•å“åº”ä¿¡æ¯
            logger.info(f"[LLMè¿”å›] Gemini API å“åº”æˆåŠŸ, è€—æ—¶ {elapsed:.2f}s, å“åº”é•¿åº¦ {len(response_text)} å­—ç¬¦")
            
            # è®°å½•å“åº”é¢„è§ˆï¼ˆINFOçº§åˆ«ï¼‰å’Œå®Œæ•´å“åº”ï¼ˆDEBUGçº§åˆ«ï¼‰
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é¢„è§ˆ]\n{response_preview}")
            logger.debug(f"=== Gemini å®Œæ•´å“åº” ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ===")
            
            # è§£æå“åº”
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            
            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è¯„åˆ† {result.sentiment_score}")
            
            return result
            
        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±è´¥: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary=f'åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)[:100]}',
                risk_warning='åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨åˆ†æ',
                success=False,
                error_message=str(e),
            )
    
    def _format_prompt(
        self, 
        context: Dict[str, Any], 
        name: str,
        news_context: Optional[str] = None
    ) -> str:
        """
        æ ¼å¼åŒ–åˆ†ææç¤ºè¯ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ v2.0ï¼‰
        
        åŒ…å«ï¼šæŠ€æœ¯æŒ‡æ ‡ã€å®æ—¶è¡Œæƒ…ï¼ˆé‡æ¯”/æ¢æ‰‹ç‡ï¼‰ã€ç­¹ç åˆ†å¸ƒã€è¶‹åŠ¿åˆ†æã€æ–°é—»
        
        Args:
            context: æŠ€æœ¯é¢æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å¢å¼ºæ•°æ®ï¼‰
            name: è‚¡ç¥¨åç§°ï¼ˆé»˜è®¤å€¼ï¼Œå¯èƒ½è¢«ä¸Šä¸‹æ–‡è¦†ç›–ï¼‰
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹
        """
        code = context.get('code', 'Unknown')
        
        # ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„è‚¡ç¥¨åç§°ï¼ˆä» realtime_quote è·å–ï¼‰
        stock_name = context.get('stock_name', name)
        if not stock_name or stock_name == f'è‚¡ç¥¨{code}':
            stock_name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
            
        today = context.get('today', {})
        
        # ========== æ„å»ºå†³ç­–ä»ªè¡¨ç›˜æ ¼å¼çš„è¾“å…¥ ==========
        prompt = f"""# å†³ç­–ä»ªè¡¨ç›˜åˆ†æè¯·æ±‚

## ğŸ“Š è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
| é¡¹ç›® | æ•°æ® |
|------|------|
| è‚¡ç¥¨ä»£ç  | **{code}** |
| è‚¡ç¥¨åç§° | **{stock_name}** |
| åˆ†ææ—¥æœŸ | {context.get('date', 'æœªçŸ¥')} |

---

## ğŸ“ˆ æŠ€æœ¯é¢æ•°æ®

### ä»Šæ—¥è¡Œæƒ…
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ”¶ç›˜ä»· | {today.get('close', 'N/A')} å…ƒ |
| å¼€ç›˜ä»· | {today.get('open', 'N/A')} å…ƒ |
| æœ€é«˜ä»· | {today.get('high', 'N/A')} å…ƒ |
| æœ€ä½ä»· | {today.get('low', 'N/A')} å…ƒ |
| æ¶¨è·Œå¹… | {today.get('pct_chg', 'N/A')}% |
| æˆäº¤é‡ | {self._format_volume(today.get('volume'))} |
| æˆäº¤é¢ | {self._format_amount(today.get('amount'))} |

### å‡çº¿ç³»ç»Ÿï¼ˆå…³é”®åˆ¤æ–­æŒ‡æ ‡ï¼‰
| å‡çº¿ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| MA5 | {today.get('ma5', 'N/A')} | çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA10 | {today.get('ma10', 'N/A')} | ä¸­çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA20 | {today.get('ma20', 'N/A')} | ä¸­æœŸè¶‹åŠ¿çº¿ |
| å‡çº¿å½¢æ€ | {context.get('ma_status', 'æœªçŸ¥')} | å¤šå¤´/ç©ºå¤´/ç¼ ç»• |
"""
        
        # æ·»åŠ å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆé‡æ¯”ã€æ¢æ‰‹ç‡ç­‰ï¼‰
        if 'realtime' in context:
            rt = context['realtime']
            prompt += f"""
### å®æ—¶è¡Œæƒ…å¢å¼ºæ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ | è§£è¯» |
|------|------|------|
| å½“å‰ä»·æ ¼ | {rt.get('price', 'N/A')} å…ƒ | |
| **é‡æ¯”** | **{rt.get('volume_ratio', 'N/A')}** | {rt.get('volume_ratio_desc', '')} |
| **æ¢æ‰‹ç‡** | **{rt.get('turnover_rate', 'N/A')}%** | |
| å¸‚ç›ˆç‡(åŠ¨æ€) | {rt.get('pe_ratio', 'N/A')} | |
| å¸‚å‡€ç‡ | {rt.get('pb_ratio', 'N/A')} | |
| æ€»å¸‚å€¼ | {self._format_amount(rt.get('total_mv'))} | |
| æµé€šå¸‚å€¼ | {self._format_amount(rt.get('circ_mv'))} | |
| 60æ—¥æ¶¨è·Œå¹… | {rt.get('change_60d', 'N/A')}% | ä¸­æœŸè¡¨ç° |
"""
        
        # æ·»åŠ ç­¹ç åˆ†å¸ƒæ•°æ®
        if 'chip' in context:
            chip = context['chip']
            profit_ratio = chip.get('profit_ratio', 0)
            prompt += f"""
### ç­¹ç åˆ†å¸ƒæ•°æ®ï¼ˆèµ„é‡‘é¢å‚è€ƒï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·æ ‡å‡† |
|------|------|----------|
| **è·åˆ©æ¯”ä¾‹** | **{profit_ratio:.1%}** | 70-90%æ—¶è­¦æƒ• |
| å¹³å‡æˆæœ¬ | {chip.get('avg_cost', 'N/A')} å…ƒ | ç°ä»·åº”é«˜äº5-15% |
| 90%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_90', 0):.2%} | <15%ä¸ºé›†ä¸­ |
| 70%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_70', 0):.2%} | |
| ç­¹ç çŠ¶æ€ | {chip.get('chip_status', 'æœªçŸ¥')} | |
"""
        
        # æ·»åŠ è´¢åŠ¡æ•°æ®ï¼ˆä»·å€¼æŠ•èµ„é¢æ ¸å¿ƒæ•°æ®ï¼‰
        if 'financial' in context and context['financial']:
            fin = context['financial']
            prompt += f"""
### è´¢åŠ¡æŒ‡æ ‡æ•°æ®ï¼ˆä»·å€¼æŠ•èµ„é¢æ ¸å¿ƒï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **ROEï¼ˆå‡€èµ„äº§æ”¶ç›Šç‡ï¼‰** | **{fin.get('roe', 'N/A')}%** | >15%ä¼˜ç§€, 10-15%è‰¯å¥½, <10%ä¸€èˆ¬ |
| **è¥æ”¶å¢é•¿ç‡** | **{fin.get('revenue_growth', 'N/A')}%** | åŒæ¯”å¢é•¿ç‡ |
| **å‡€åˆ©æ¶¦å¢é•¿ç‡** | **{fin.get('profit_growth', 'N/A')}%** | åŒæ¯”å¢é•¿ç‡ |
| é”€å”®æ¯›åˆ©ç‡ | {fin.get('gross_profit_margin', 'N/A')}% | ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡ |
| é”€å”®å‡€åˆ©ç‡ | {fin.get('net_profit_margin', 'N/A')}% | ç›ˆåˆ©è´¨é‡æŒ‡æ ‡ |
| è´¢æŠ¥æ—¥æœŸ | {fin.get('report_date', 'N/A')} | æ•°æ®æ—¶æ•ˆæ€§ |

**æ•°æ®æ¥æº**: {fin.get('data_source', 'unknown')}
"""
        else:
            prompt += """
### è´¢åŠ¡æŒ‡æ ‡æ•°æ®
âš ï¸ **è´¢åŠ¡æ•°æ®æš‚æ—¶æ— æ³•è·å–**ï¼Œä»·å€¼é¢åˆ†æä¸»è¦ä¾æ®PE/PBä¼°å€¼å’Œè¡Œä¸šå¯¹æ¯”ã€‚
"""
        
        # æ·»åŠ èµ„é‡‘æµæ•°æ®ï¼ˆèµ„é‡‘é¢æ ¸å¿ƒæ•°æ®ï¼‰
        if 'moneyflow' in context and context['moneyflow']:
            mf = context['moneyflow']
            main_inflow = mf.get('main_net_inflow', 0) or 0
            main_inflow_yi = main_inflow / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
            
            prompt += f"""
### èµ„é‡‘æµå‘æ•°æ®ï¼ˆèµ„é‡‘é¢æ ¸å¿ƒï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **ä¸»åŠ›èµ„é‡‘å‡€æµå…¥** | **{main_inflow_yi:.2f}äº¿å…ƒ** | ç‰¹å¤§å•+å¤§å•å‡€æµå…¥ |
| ä¸»åŠ›å‡€æµå…¥å æ¯” | {mf.get('main_net_inflow_rate', 'N/A')}% | å æˆäº¤é¢æ¯”ä¾‹ |
| å¤§å•å‡€æµå…¥ | {(mf.get('net_mf_lg', 0) or 0) / 10000:.2f}äº¿å…ƒ | å•ç¬”>20ä¸‡ |
| ä¸­å•å‡€æµå…¥ | {(mf.get('net_mf_md', 0) or 0) / 10000:.2f}äº¿å…ƒ | å•ç¬”4-20ä¸‡ |
| å°å•å‡€æµå…¥ | {(mf.get('net_mf_sm', 0) or 0) / 10000:.2f}äº¿å…ƒ | å•ç¬”<4ä¸‡ |
| äº¤æ˜“æ—¥æœŸ | {mf.get('trade_date', 'N/A')} | æ•°æ®æ—¶æ•ˆæ€§ |

**èµ„é‡‘æµå‘è¶‹åŠ¿**: {'æµå…¥' if main_inflow_yi > 0 else 'æµå‡º'}
"""
            
            # æ·»åŠ åŒ—å‘èµ„é‡‘ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'north_moneyflow' in context and context['north_moneyflow']:
                north = context['north_moneyflow']
                north_inflow_yi = north.get('total_net_amount', 0) / 10000
                
                prompt += f"""
### åŒ—å‘èµ„é‡‘ï¼ˆå¤–èµ„åŠ¨å‘ï¼‰
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æœ€è¿‘{north.get('days', 5)}æ—¥ç´¯è®¡å‡€æµå…¥ | {north_inflow_yi:.2f}äº¿å…ƒ |
| æ—¥å‡å‡€æµå…¥ | {north.get('avg_net_amount', 0) / 10000:.2f}äº¿å…ƒ |
| **è¶‹åŠ¿åˆ¤æ–­** | **{north.get('trend', 'æœªçŸ¥')}** |
"""
        else:
            prompt += """
### èµ„é‡‘æµå‘æ•°æ®
âš ï¸ **èµ„é‡‘æµæ•°æ®æš‚æ—¶æ— æ³•è·å–**ï¼ˆéœ€è¦Tushare Pro 600ç§¯åˆ†ï¼‰ï¼Œèµ„é‡‘é¢åˆ†æä¸»è¦ä¾æ®ç­¹ç åˆ†å¸ƒæ•°æ®ã€‚
"""
        
        # æ·»åŠ è¶‹åŠ¿åˆ†æç»“æœï¼ˆåŸºäºäº¤æ˜“ç†å¿µçš„é¢„åˆ¤ï¼‰
        if 'trend_analysis' in context:
            trend = context['trend_analysis']
            bias_warning = "ğŸš¨ è¶…è¿‡5%ï¼Œä¸¥ç¦è¿½é«˜ï¼" if trend.get('bias_ma5', 0) > 5 else "âœ… å®‰å…¨èŒƒå›´"
            prompt += f"""
### è¶‹åŠ¿åˆ†æé¢„åˆ¤ï¼ˆåŸºäºäº¤æ˜“ç†å¿µï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | åˆ¤å®š |
|------|------|------|
| è¶‹åŠ¿çŠ¶æ€ | {trend.get('trend_status', 'æœªçŸ¥')} | |
| å‡çº¿æ’åˆ— | {trend.get('ma_alignment', 'æœªçŸ¥')} | MA5>MA10>MA20ä¸ºå¤šå¤´ |
| è¶‹åŠ¿å¼ºåº¦ | {trend.get('trend_strength', 0)}/100 | |
| **ä¹–ç¦»ç‡(MA5)** | **{trend.get('bias_ma5', 0):+.2f}%** | {bias_warning} |
| ä¹–ç¦»ç‡(MA10) | {trend.get('bias_ma10', 0):+.2f}% | |
| é‡èƒ½çŠ¶æ€ | {trend.get('volume_status', 'æœªçŸ¥')} | {trend.get('volume_trend', '')} |
| ç³»ç»Ÿä¿¡å· | {trend.get('buy_signal', 'æœªçŸ¥')} | |
| ç³»ç»Ÿè¯„åˆ† | {trend.get('signal_score', 0)}/100 | |

#### ç³»ç»Ÿåˆ†æç†ç”±
**ä¹°å…¥ç†ç”±**ï¼š
{chr(10).join('- ' + r for r in trend.get('signal_reasons', ['æ— '])) if trend.get('signal_reasons') else '- æ— '}

**é£é™©å› ç´ **ï¼š
{chr(10).join('- ' + r for r in trend.get('risk_factors', ['æ— '])) if trend.get('risk_factors') else '- æ— '}
"""
        
        # æ·»åŠ æ˜¨æ—¥å¯¹æ¯”æ•°æ®
        if 'yesterday' in context:
            volume_change = context.get('volume_change_ratio', 'N/A')
            prompt += f"""
### é‡ä»·å˜åŒ–
- æˆäº¤é‡è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{volume_change}å€
- ä»·æ ¼è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{context.get('price_change_ratio', 'N/A')}%
"""
        
        # æ·»åŠ æ–°é—»æœç´¢ç»“æœï¼ˆé‡ç‚¹åŒºåŸŸï¼‰
        prompt += """
---

## ğŸ“° èˆ†æƒ…æƒ…æŠ¥
"""
        if news_context:
            prompt += f"""
ä»¥ä¸‹æ˜¯ **{stock_name}({code})** è¿‘7æ—¥çš„æ–°é—»æœç´¢ç»“æœï¼Œè¯·é‡ç‚¹æå–ï¼š
1. ğŸš¨ **é£é™©è­¦æŠ¥**ï¼šå‡æŒã€å¤„ç½šã€åˆ©ç©º
2. ğŸ¯ **åˆ©å¥½å‚¬åŒ–**ï¼šä¸šç»©ã€åˆåŒã€æ”¿ç­–
3. ğŸ“Š **ä¸šç»©é¢„æœŸ**ï¼šå¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥

```
{news_context}
```
"""
        else:
            prompt += """
æœªæœç´¢åˆ°è¯¥è‚¡ç¥¨è¿‘æœŸçš„ç›¸å…³æ–°é—»ã€‚è¯·ä¸»è¦ä¾æ®æŠ€æœ¯é¢æ•°æ®è¿›è¡Œåˆ†æã€‚
"""

        # æ³¨å…¥ç¼ºå¤±æ•°æ®è­¦å‘Š
        if context.get('data_missing'):
            prompt += """
âš ï¸ **æ•°æ®ç¼ºå¤±è­¦å‘Š**
ç”±äºæ¥å£é™åˆ¶ï¼Œå½“å‰æ— æ³•è·å–å®Œæ•´çš„å®æ—¶è¡Œæƒ…å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®ã€‚
è¯· **å¿½ç•¥ä¸Šè¿°è¡¨æ ¼ä¸­çš„ N/A æ•°æ®**ï¼Œé‡ç‚¹ä¾æ® **ã€ğŸ“° èˆ†æƒ…æƒ…æŠ¥ã€‘** ä¸­çš„æ–°é—»è¿›è¡ŒåŸºæœ¬é¢å’Œæƒ…ç»ªé¢åˆ†æã€‚
åœ¨å›ç­”æŠ€æœ¯é¢é—®é¢˜ï¼ˆå¦‚å‡çº¿ã€ä¹–ç¦»ç‡ï¼‰æ—¶ï¼Œè¯·ç›´æ¥è¯´æ˜â€œæ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­â€ï¼Œ**ä¸¥ç¦ç¼–é€ æ•°æ®**ã€‚
"""
        
        # æ˜ç¡®çš„è¾“å‡ºè¦æ±‚
        prompt += f"""
---

## âœ… åˆ†æä»»åŠ¡

è¯·ä¸º **{stock_name}({code})** ç”Ÿæˆã€ç»¼åˆæŠ•èµ„åˆ†æä»ªè¡¨ç›˜ã€‘ï¼Œä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºã€‚

### 4ç»´åº¦è¯„ä¼°è¦æ±‚ï¼š

**1. ä»·å€¼æŠ•èµ„é¢ï¼ˆ40%æƒé‡ï¼‰**
- PE/PB ä¼°å€¼æ°´å¹³ï¼ˆä¸è¡Œä¸šæ¯”è¾ƒï¼‰
- ROE ç›ˆåˆ©è´¨é‡
- ä¸šç»©å¢é•¿æ€§ï¼ˆè¥æ”¶/åˆ©æ¶¦å¢é•¿ç‡ï¼‰
- æŠ¤åŸæ²³å¼ºåº¦
- ç»™å‡º 0-100 åˆ†è¯„åˆ†

**2. èµ„é‡‘é¢ï¼ˆ25%æƒé‡ï¼‰**
- ä¸»åŠ›èµ„é‡‘æµå‘ï¼ˆå¦‚æœ‰æ•°æ®ï¼‰
- åŒ—å‘èµ„é‡‘åŠ¨å‘ï¼ˆAè‚¡ï¼‰
- ç­¹ç é›†ä¸­åº¦ã€è·åˆ©æ¯”ä¾‹
- ç»™å‡º 0-100 åˆ†è¯„åˆ†

**3. æ¶ˆæ¯é¢ï¼ˆ25%æƒé‡ï¼‰**
- æ–°é—»èˆ†æƒ…ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰
- é£é™©æ’æŸ¥ï¼ˆå‡æŒã€å¤„ç½šã€ä¸šç»©é¢„è­¦ï¼‰
- åˆ©å¥½å‚¬åŒ–ï¼ˆæ”¿ç­–ã€åˆåŒã€æ–°å“ï¼‰
- ç»™å‡º 0-100 åˆ†è¯„åˆ†

**4. è¶‹åŠ¿é¢ï¼ˆ10%æƒé‡ï¼‰**
- å‡çº¿ç³»ç»Ÿæ’åˆ—
- æŠ€æœ¯å½¢æ€ã€é‡ä»·å…³ç³»
- ç»™å‡º 0-100 åˆ†è¯„åˆ†

### ç»¼åˆè¯„åˆ†è®¡ç®—ï¼š
sentiment_score = ä»·å€¼é¢Ã—0.4 + èµ„é‡‘é¢Ã—0.25 + æ¶ˆæ¯é¢Ã—0.25 + è¶‹åŠ¿é¢Ã—0.1

### è¾“å‡ºè¦æ±‚ï¼š
- æ¯ä¸ªç»´åº¦å¿…é¡»æœ‰ score å’Œ summary
- æ ¸å¿ƒç»“è®ºåŸºäº4ç»´åº¦ç»¼åˆåˆ¤æ–­
- å¦‚æŸç»´åº¦æ•°æ®ç¼ºå¤±ï¼Œåœ¨ summary ä¸­è¯´æ˜ï¼Œscore ç»™ä¸­æ€§åˆ†ï¼ˆ40-60ï¼‰

è¯·è¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼ç»¼åˆæŠ•èµ„åˆ†æä»ªè¡¨ç›˜ã€‚"""
        
        return prompt
    
    def _format_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡æ˜¾ç¤º"""
        if volume is None:
            return 'N/A'
        if volume >= 1e8:
            return f"{volume / 1e8:.2f} äº¿è‚¡"
        elif volume >= 1e4:
            return f"{volume / 1e4:.2f} ä¸‡è‚¡"
        else:
            return f"{volume:.0f} è‚¡"
    
    def _format_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¢æ˜¾ç¤º"""
        if amount is None:
            return 'N/A'
        if amount >= 1e8:
            return f"{amount / 1e8:.2f} äº¿å…ƒ"
        elif amount >= 1e4:
            return f"{amount / 1e4:.2f} ä¸‡å…ƒ"
        else:
            return f"{amount:.0f} å…ƒ"
    
    def _parse_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """
        è§£æ AI å“åº”ï¼ˆç»¼åˆæŠ•èµ„åˆ†æç‰ˆï¼‰
        
        å°è¯•ä»å“åº”ä¸­æå– JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«4ç»´åº¦è¯„åˆ†å’Œ dashboard å­—æ®µ
        å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ™ºèƒ½æå–æˆ–è¿”å›é»˜è®¤ç»“æœ
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®°
            cleaned_text = response_text
            if '```json' in cleaned_text:
                cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
            elif '```' in cleaned_text:
                cleaned_text = cleaned_text.replace('```', '')
            
            # å°è¯•æ‰¾åˆ° JSON å†…å®¹
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned_text[json_start:json_end]
                
                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                json_str = self._fix_json_string(json_str)
                
                data = json.loads(json_str)
                
                # æå–4ç»´åº¦æ•°æ®
                dimensions = data.get('dimensions', {})
                
                # æå–å„ç»´åº¦è¯„åˆ†ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
                value_data = dimensions.get('value_investment', {})
                funding_data = dimensions.get('funding_flow', {})
                news_data = dimensions.get('news_sentiment', {})
                trend_data = dimensions.get('trend_analysis', {})
                
                value_score = int(value_data.get('score', 50))
                funding_score = int(funding_data.get('score', 50))
                news_score = int(news_data.get('score', 50))
                trend_score = int(trend_data.get('score', 50))
                
                # æå– dashboard æ•°æ®
                dashboard = data.get('dashboard', None)
                
                # è§£ææ‰€æœ‰å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼é˜²æ­¢ç¼ºå¤±
                return AnalysisResult(
                    code=code,
                    name=name,
                    # æ ¸å¿ƒæŒ‡æ ‡
                    sentiment_score=int(data.get('sentiment_score', 50)),
                    trend_prediction=data.get('trend_prediction', 'éœ‡è¡'),
                    operation_advice=data.get('operation_advice', 'æŒæœ‰'),
                    confidence_level=data.get('confidence_level', 'ä¸­'),
                    # 4ç»´åº¦è¯„åˆ†
                    value_score=value_score,
                    funding_score=funding_score,
                    news_score=news_score,
                    trend_score=trend_score,
                    dimensions=dimensions,
                    # å†³ç­–ä»ªè¡¨ç›˜
                    dashboard=dashboard,
                    # èµ°åŠ¿åˆ†æ
                    trend_analysis=data.get('trend_analysis', ''),
                    short_term_outlook=data.get('short_term_outlook', ''),
                    medium_term_outlook=data.get('medium_term_outlook', ''),
                    # æŠ€æœ¯é¢
                    technical_analysis=data.get('technical_analysis', ''),
                    ma_analysis=data.get('ma_analysis', ''),
                    volume_analysis=data.get('volume_analysis', ''),
                    pattern_analysis=data.get('pattern_analysis', ''),
                    # åŸºæœ¬é¢
                    fundamental_analysis=data.get('fundamental_analysis', ''),
                    sector_position=data.get('sector_position', ''),
                    company_highlights=data.get('company_highlights', ''),
                    # æƒ…ç»ªé¢/æ¶ˆæ¯é¢
                    news_summary=data.get('news_summary', ''),
                    market_sentiment=data.get('market_sentiment', ''),
                    hot_topics=data.get('hot_topics', ''),
                    # ç»¼åˆ
                    analysis_summary=data.get('analysis_summary', 'åˆ†æå®Œæˆ'),
                    key_points=data.get('key_points', ''),
                    risk_warning=data.get('risk_warning', ''),
                    buy_reason=data.get('buy_reason', ''),
                    # å…ƒæ•°æ®
                    search_performed=data.get('search_performed', False),
                    data_sources=data.get('data_sources', 'æŠ€æœ¯é¢æ•°æ®'),
                    success=True,
                )
            else:
                # æ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ä»çº¯æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå– JSONï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬åˆ†æ")
                return self._parse_text_response(response_text, code, name)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON è§£æå¤±è´¥: {e}ï¼Œå°è¯•ä»æ–‡æœ¬æå–")
            return self._parse_text_response(response_text, code, name)
    
    def _fix_json_string(self, json_str: str) -> str:
        """ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜"""
        import re
        
        # ç§»é™¤æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å°¾éšé€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å¸ƒå°”å€¼æ˜¯å°å†™
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        return json_str
    
    def _parse_text_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """ä»çº¯æ–‡æœ¬å“åº”ä¸­å°½å¯èƒ½æå–åˆ†æä¿¡æ¯"""
        # å°è¯•è¯†åˆ«å…³é”®è¯æ¥åˆ¤æ–­æƒ…ç»ª
        sentiment_score = 50
        trend = 'éœ‡è¡'
        advice = 'æŒæœ‰'
        
        text_lower = response_text.lower()
        
        # ç®€å•çš„æƒ…ç»ªè¯†åˆ«
        positive_keywords = ['çœ‹å¤š', 'ä¹°å…¥', 'ä¸Šæ¶¨', 'çªç ´', 'å¼ºåŠ¿', 'åˆ©å¥½', 'åŠ ä»“', 'bullish', 'buy']
        negative_keywords = ['çœ‹ç©º', 'å–å‡º', 'ä¸‹è·Œ', 'è·Œç ´', 'å¼±åŠ¿', 'åˆ©ç©º', 'å‡ä»“', 'bearish', 'sell']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text_lower)
        negative_count = sum(1 for kw in negative_keywords if kw in text_lower)
        
        if positive_count > negative_count + 1:
            sentiment_score = 65
            trend = 'çœ‹å¤š'
            advice = 'ä¹°å…¥'
        elif negative_count > positive_count + 1:
            sentiment_score = 35
            trend = 'çœ‹ç©º'
            advice = 'å–å‡º'
        
        # æˆªå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        summary = response_text[:500] if response_text else 'æ— åˆ†æç»“æœ'
        
        return AnalysisResult(
            code=code,
            name=name,
            sentiment_score=sentiment_score,
            trend_prediction=trend,
            operation_advice=advice,
            confidence_level='ä½',
            analysis_summary=summary,
            key_points='JSONè§£æå¤±è´¥ï¼Œä»…ä¾›å‚è€ƒ',
            risk_warning='åˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®ï¼Œå»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯åˆ¤æ–­',
            raw_response=response_text,
            success=True,
        )
    
    def batch_analyze(
        self, 
        contexts: List[Dict[str, Any]],
        delay_between: float = 2.0
    ) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨
        
        æ³¨æ„ï¼šä¸ºé¿å… API é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡åˆ†æä¹‹é—´ä¼šæœ‰å»¶è¿Ÿ
        
        Args:
            contexts: ä¸Šä¸‹æ–‡æ•°æ®åˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
            
        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []
        
        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’åç»§ç»­...")
                time.sleep(delay_between)
            
            result = self.analyze(context)
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•°
def get_analyzer() -> GeminiAnalyzer:
    """è·å– Gemini åˆ†æå™¨å®ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ•°æ®
    test_context = {
        'code': '600519',
        'date': '2026-01-09',
        'today': {
            'open': 1800.0,
            'high': 1850.0,
            'low': 1780.0,
            'close': 1820.0,
            'volume': 10000000,
            'amount': 18200000000,
            'pct_chg': 1.5,
            'ma5': 1810.0,
            'ma10': 1800.0,
            'ma20': 1790.0,
            'volume_ratio': 1.2,
        },
        'ma_status': 'å¤šå¤´æ’åˆ— ğŸ“ˆ',
        'volume_change_ratio': 1.3,
        'price_change_ratio': 1.5,
    }
    
    analyzer = GeminiAnalyzer()
    
    if analyzer.is_available():
        print("=== AI åˆ†ææµ‹è¯• ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æç»“æœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
